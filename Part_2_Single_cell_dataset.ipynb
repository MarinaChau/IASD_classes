{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2 Single cell dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxW6q/PzFqpQ9GFtka5vX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarinaChau/IASD_classes/blob/master/Part_2_Single_cell_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install scprep\n",
        "!pip install tensorflow==1.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoXEKCS2pzJU",
        "outputId": "860f13ae-ff9c-4375-b531-e4760f74731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scprep in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from scprep) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from scprep) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scprep) (1.0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scprep) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scprep) (21.3)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from scprep) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->scprep) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->scprep) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->scprep) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scprep) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scprep) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->scprep) (3.0.7)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.12 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.8.0rc0, 2.8.0rc1, 2.8.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.12\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2. Analyses of datasets using unsupervised approach"
      ],
      "metadata": {
        "id": "IBHJeOnMlMEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a dataset describing development of a dentate gyrus, a part of the mouse brain. Each object is a brain cell\n",
        "characterized by the expression of ~10000 genes. The cells are labeled into 24 distinct cell types.\n",
        "\n",
        " In this notebook, we will use different libraries to visualize our dataset."
      ],
      "metadata": {
        "id": "r-WIiaTepHYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "  drive._mount('/content/drive') \n",
        "except Exception:\n",
        "  drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "GMhNXX0aGfpK",
        "outputId": "51db1187-fe6e-4e63-a3a8-6f7ed00e32b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import io\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "### Third-party libraries"
      ],
      "metadata": {
        "id": "KLvswJSDpNW8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercice\n",
        "* 1) Choose one of the datasets 1-3 or suggest you own\n",
        "* 2) Check if you have missing values and suggest a strategy for imputing them\n",
        "* 3) Check if the dataset needs to be normalized in a particular way\n",
        "* 4) Give an estimate of intrinsic dimensionality of the dataset (if you want you can use skdim package\n",
        "* https://github.com/j-bac/scikit-dimension/tree/master/skdim)\n",
        "* 5) Apply PCA and visualize the dataset in the space of two first principal components\n",
        "* 6) Investigate higher-order principal components, try to conclude if they contain useful information\n",
        "* 7) Apply any non-linear manifold learning method and visualize the dataset\n",
        "* 8) Apply two or more different clustering methods using clustering quality criteria, compare the results as\n",
        "* well as computational time\n",
        "* 9) Apply any matrix factorization method which is not PCA, compare it with PCA as well as computational time"
      ],
      "metadata": {
        "id": "b_B5e2mnpgHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Q.1 Import dataset"
      ],
      "metadata": {
        "id": "mDvQdR4Mr-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "mZYLuNzKqhzO",
        "outputId": "ec8afa6a-fc07-45cb-fc83-06da56d744a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bccdceb4-3640-4b75-b675-0138c450072f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bccdceb4-3640-4b75-b675-0138c450072f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dentate_gyrus_sample3000.csv to dentate_gyrus_sample3000 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(io.StringIO(uploaded[\"dentate_gyrus_sample3000.csv\"].decode(\"utf-8\")))\n",
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "1Ormcq6-rGx-",
        "outputId": "3508cfc5-a192-4539-e6a0-4d7c9e5bb20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1daab121-decb-4ecb-bbcd-1ce5dcb36870\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Tmsb10</th>\n",
              "      <th>Apoe</th>\n",
              "      <th>Mt1</th>\n",
              "      <th>Stmn2</th>\n",
              "      <th>Tuba1a</th>\n",
              "      <th>Stmn1</th>\n",
              "      <th>Meg3</th>\n",
              "      <th>Ptn</th>\n",
              "      <th>Mt3</th>\n",
              "      <th>Tubb2b</th>\n",
              "      <th>Fabp7</th>\n",
              "      <th>Cst3</th>\n",
              "      <th>Xist</th>\n",
              "      <th>Sox11</th>\n",
              "      <th>Tubb3</th>\n",
              "      <th>Pcp4</th>\n",
              "      <th>Igfbpl1</th>\n",
              "      <th>Slc1a2</th>\n",
              "      <th>Slc1a3</th>\n",
              "      <th>Tubb5</th>\n",
              "      <th>Snca</th>\n",
              "      <th>Plp1</th>\n",
              "      <th>Atp1a2</th>\n",
              "      <th>Dbi</th>\n",
              "      <th>Nnat</th>\n",
              "      <th>Cd24a</th>\n",
              "      <th>Mt2</th>\n",
              "      <th>Ppp3ca</th>\n",
              "      <th>Ncdn</th>\n",
              "      <th>Gap43</th>\n",
              "      <th>Mllt11</th>\n",
              "      <th>Marcksl1</th>\n",
              "      <th>Aldoc</th>\n",
              "      <th>Camk2a</th>\n",
              "      <th>Plppr4</th>\n",
              "      <th>Clu</th>\n",
              "      <th>Glul</th>\n",
              "      <th>Ptprz1</th>\n",
              "      <th>Sparcl1</th>\n",
              "      <th>...</th>\n",
              "      <th>Shf</th>\n",
              "      <th>2610037D02Rik</th>\n",
              "      <th>Atxn7l2</th>\n",
              "      <th>Tmem74b</th>\n",
              "      <th>Adnp2</th>\n",
              "      <th>Arsg</th>\n",
              "      <th>Esco2</th>\n",
              "      <th>Tmtc3</th>\n",
              "      <th>Rnmtl1</th>\n",
              "      <th>Pald1</th>\n",
              "      <th>Dcp1a</th>\n",
              "      <th>Gemin2</th>\n",
              "      <th>Nckipsd</th>\n",
              "      <th>Notch3</th>\n",
              "      <th>Ubtd1</th>\n",
              "      <th>Simc1</th>\n",
              "      <th>Nkrf</th>\n",
              "      <th>Gabpb2</th>\n",
              "      <th>Fbxo10</th>\n",
              "      <th>Cenpl</th>\n",
              "      <th>Wdr36</th>\n",
              "      <th>Invs</th>\n",
              "      <th>Trim39</th>\n",
              "      <th>Ttc21b</th>\n",
              "      <th>Penk</th>\n",
              "      <th>Zfp629</th>\n",
              "      <th>D130020L05Rik</th>\n",
              "      <th>Pnpt1</th>\n",
              "      <th>Ice2</th>\n",
              "      <th>Pifo</th>\n",
              "      <th>Nol10</th>\n",
              "      <th>Gm6356</th>\n",
              "      <th>Tpmt</th>\n",
              "      <th>Gba</th>\n",
              "      <th>Slc25a20</th>\n",
              "      <th>Col19a1</th>\n",
              "      <th>Zfp516</th>\n",
              "      <th>Rgp1</th>\n",
              "      <th>Col26a1</th>\n",
              "      <th>Jpx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Neuroblast</td>\n",
              "      <td>4.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>3.09</td>\n",
              "      <td>4.62</td>\n",
              "      <td>3.72</td>\n",
              "      <td>4.04</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>3.81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.43</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.63</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.88</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.59</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Immature-GC</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.76</td>\n",
              "      <td>0.84</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.65</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.63</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>2.96</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.54</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.44</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>1.29</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GC-juv</td>\n",
              "      <td>1.71</td>\n",
              "      <td>5.08</td>\n",
              "      <td>2.98</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3.97</td>\n",
              "      <td>3.32</td>\n",
              "      <td>1.57</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.62</td>\n",
              "      <td>3.15</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.92</td>\n",
              "      <td>4.98</td>\n",
              "      <td>2.72</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2.41</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2.23</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2.28</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.35</td>\n",
              "      <td>2.87</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA3-Pyr</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.35</td>\n",
              "      <td>4.26</td>\n",
              "      <td>3.88</td>\n",
              "      <td>3.82</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.47</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.10</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.23</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.61</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.37</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.84</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GC-juv</td>\n",
              "      <td>1.91</td>\n",
              "      <td>4.08</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>2.67</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.10</td>\n",
              "      <td>4.69</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1.79</td>\n",
              "      <td>5.36</td>\n",
              "      <td>4.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.44</td>\n",
              "      <td>3.25</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.39</td>\n",
              "      <td>0.81</td>\n",
              "      <td>2.82</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.41</td>\n",
              "      <td>2.44</td>\n",
              "      <td>2.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.10</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2.83</td>\n",
              "      <td>2.98</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1daab121-decb-4ecb-bbcd-1ce5dcb36870')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1daab121-decb-4ecb-bbcd-1ce5dcb36870 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1daab121-decb-4ecb-bbcd-1ce5dcb36870');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         label  Tmsb10  Apoe   Mt1  Stmn2  ...  Col19a1  Zfp516  Rgp1  Col26a1   Jpx\n",
              "0   Neuroblast    4.47  0.00  0.35   3.09  ...      0.0     0.0  0.00     0.49  0.00\n",
              "1  Immature-GC    2.36  0.36  0.84   1.40  ...      0.0     0.0  0.36     0.00  0.00\n",
              "2       GC-juv    1.71  5.08  2.98   0.52  ...      0.0     0.0  0.20     0.00  0.00\n",
              "3      CA3-Pyr    4.29  0.20  0.20   3.35  ...      0.0     0.0  0.00     0.37  0.00\n",
              "4       GC-juv    1.91  4.08  3.24   0.41  ...      0.0     0.0  0.00     0.00  0.41\n",
              "\n",
              "[5 rows x 10001 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.to_pickle(path=\"/content/drive/MyDrive/Master 5A/FML/brain_cell_df.pkl\")"
      ],
      "metadata": {
        "id": "I1YRco37GN5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dataset has {dataframe.shape[0]} cells and {dataframe.shape[1]} features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnGkE_2LKXuC",
        "outputId": "d8a69883-2c40-45be-bdfe-4cb53c20de25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 3000 cells and 10001 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5Ren8-aKsXQ",
        "outputId": "8601d991-aa8d-49a8-eae6-d50071a40da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Columns: 10001 entries, label to Jpx\n",
            "dtypes: float64(10000), object(1)\n",
            "memory usage: 228.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of categories of cell: \",len(dataframe['label'].value_counts()))\n",
        "dataframe['label'].value_counts()"
      ],
      "metadata": {
        "id": "kofhwkEr7MV_",
        "outputId": "9e455fdf-1e73-4299-eabd-24e9d7b015d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories of cell:  24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Immature-Pyr            589\n",
              "GC-juv                  429\n",
              "Immature-GC             319\n",
              "GC-adult                304\n",
              "Neuroblast              178\n",
              "Astro-adult             151\n",
              "Immature-GABA           121\n",
              "Astro-juv               104\n",
              "RGL_young                85\n",
              "MOL                      82\n",
              "OPC                      81\n",
              "Immature-Astro           75\n",
              "Endothelial              74\n",
              "CA3-Pyr                  65\n",
              "Cajal-Retzius            61\n",
              "nIPC-perin               57\n",
              "MiCajal-Retziusoglia     50\n",
              "nIPC                     40\n",
              "NFOL                     33\n",
              "RGL                      25\n",
              "VLMC                     22\n",
              "GABA                     22\n",
              "Ependymal                19\n",
              "PVM                      14\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data"
      ],
      "metadata": {
        "id": "9wPCRTO6JsS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.2 Check if you have missing values and suggest a strategy for imputing them\n",
        "\n",
        "Helful link: `https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779`\n",
        "\n",
        "We can either check if there is any missing value for each cell by searching NaN per row or check if there is any missing value per features by checking each row.\n",
        "\n",
        "It depends on what we want for our dataset. If there are features with a lot of missing elements, we can either impute values or choose to delete that features. As 10 000 is a huge number of features, and we will work on reducing its number, if one feature is missing, we can neglect it (well if we consider each feature having the same weight importance). \n",
        "\n",
        "Another solution would be to imput data, however it requires some domain experience.\n"
      ],
      "metadata": {
        "id": "mUqh8ryxvg8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentages of missing values\n",
        "print((dataframe.isnull().mean() * 100).sort_values(ascending = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u718hWDZNAKL",
        "outputId": "e35defb7-a883-4dc6-8839-545a9cfc80f7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label      0.0\n",
            "Fam135a    0.0\n",
            "Abcf2      0.0\n",
            "Mfsd11     0.0\n",
            "Ascc1      0.0\n",
            "          ... \n",
            "Dbndd2     0.0\n",
            "Map2k4     0.0\n",
            "Chmp2b     0.0\n",
            "Rassf8     0.0\n",
            "Jpx        0.0\n",
            "Length: 10001, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no missing values in our dataset.\n"
      ],
      "metadata": {
        "id": "rR9zHAHx4Elp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What we can say:**\n",
        "\n",
        "There are three main types of missing data:\n",
        "- Missing completely at random (MCAR) : These are the missing data points that follow no discernable pattern.\n",
        "- Missing at random (MAR) : The missing value can roughly be interpolated from the remaining values to a reasonable degree of accuracy.  If conditioning on another feature increases the likelihood of a particular value compared to a proportional distribution, this value is likely MAR.\n",
        "- Not missing at random (NMAR): data where the mechanism for why the data is missing is known. Still, the values can not effectively be inferred or predicted.\n",
        "\n",
        "**How we would replace the missing values:**\n",
        "\n",
        "Each possible solution depends on the use case. \n",
        "- If there is a lot of missing data for one feature, as we have 10000 features and we suppose that each feature has the same importance weight and are not strongly correlated with each other, best would be to drop this feature. Replacing missing data by statistics such as mean, median, max or min would induce bias and won't factor the correlations between features, it only works on the column level. \n",
        "- If there is some MCAR data, as each cell belongs to one of the 24 categories, we could group the cells by its categories, and then try to do some imputation using k-NN. The k nearest neighbours is an algorithm that is used for simple classification. The algorithm uses ‘feature similarity’ to predict the values of any new data points. This means that the new point is assigned a value based on how closely it resembles the points in the training set. However it can be quite sensitive to outliers in the data.\n",
        "- We can also work with the MICE procedure: MICE is a multiple imputation method used to replace missing data values in a data set under certain assumptions about the data missingness mechanism (e.g., the data are missing at random, the data are missing completely at random).\n"
      ],
      "metadata": {
        "id": "FP653KO_4Jg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.3 Check if the dataset needs to be normalized in a particular way\n",
        "\n",
        "Helpful link: \n",
        "- `https://towardsdatascience.com/how-to-normalize-single-cell-a438281ea654`\n",
        "- `https://towardsdatascience.com/tagged/stats-ml-life-sciences`\n",
        "- `https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/`\n",
        "- `https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff`\n",
        "- `https://www.machinecurve.com/index.php/2020/11/23/feature-scaling-with-python-and-sparse-data/`"
      ],
      "metadata": {
        "id": "6MNmV-GuLzqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Does the data need to be normalized? \n",
        "\n",
        "dataframe.iloc[:,1:].max().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "9I1QiH43AMT9",
        "outputId": "2e2ee1ea-400c-4b45-b547-e27f3ae6d93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Malat1     7.70\n",
              "Plp1       7.44\n",
              "Cst3       7.29\n",
              "Ttr        7.17\n",
              "Ptgds      7.15\n",
              "           ... \n",
              "Ppwd1      0.76\n",
              "Nle1       0.76\n",
              "Tmem74b    0.75\n",
              "Gba        0.75\n",
              "Pgm3       0.72\n",
              "Length: 10000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_ranges = dataframe.iloc[:,1:].max() - dataframe.iloc[:,1:].min() # Looking at the data range for each feature\n",
        "print((col_ranges.sort_values(ascending=False)))"
      ],
      "metadata": {
        "id": "IjCAomTjDb4p",
        "outputId": "80b2b89c-4e7f-4f0b-d7c5-d8f77b1c788b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plp1       7.44\n",
            "Malat1     7.33\n",
            "Cst3       7.29\n",
            "Ttr        7.17\n",
            "Ptgds      7.15\n",
            "           ... \n",
            "Ppwd1      0.76\n",
            "Nle1       0.76\n",
            "Tmem74b    0.75\n",
            "Gba        0.75\n",
            "Pgm3       0.72\n",
            "Length: 10000, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.iloc[:,1:].std() # Checking the standard variation of our data"
      ],
      "metadata": {
        "id": "Ete4Sjl1EGSj",
        "outputId": "f03116ca-fa11-4550-b983-9e91ee73bf03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tmsb10     1.662372\n",
              "Apoe       1.469267\n",
              "Mt1        1.467278\n",
              "Stmn2      1.436146\n",
              "Tuba1a     1.419872\n",
              "             ...   \n",
              "Col19a1    0.131733\n",
              "Zfp516     0.139209\n",
              "Rgp1       0.144421\n",
              "Col26a1    0.142950\n",
              "Jpx        0.140936\n",
              "Length: 10000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that features in our dataset have different range, going from 0.72 for Pgm3 (the smallest range) to 7.44 for Plp1. It is quite large (x10 factor) and implies that some features will definitly outweight others. Even the standard variation difference between data is important.\n",
        "\n",
        "There are plenty of methods to \"normalize our data\" but the two principals are: either we normalize it, or we standardize it. \n",
        "\n",
        "- Standard Scaler- Transforms features independently to unit variance and zero centered.Its data value range is fixed between 0 and 1 . Most commonly used.\n",
        "- MInMax Scaler - Alternate to standard scaling which has agility to set the minimum and maximum range of data value. e.g. -1 to +1, -10 to +10\n",
        "Min max scaler should be used when it is required to capture small variance in features and also for sparse data where zero value needs to be preserved."
      ],
      "metadata": {
        "id": "bJQaW_z4H-Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "gh3YxOmVpBSa",
        "outputId": "0d5852ab-ce85-4573-8ecd-d2fb2dbea9d7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31f5c457-9a28-444d-9041-f9f3f09a1795\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Tmsb10</th>\n",
              "      <th>Apoe</th>\n",
              "      <th>Mt1</th>\n",
              "      <th>Stmn2</th>\n",
              "      <th>Tuba1a</th>\n",
              "      <th>Stmn1</th>\n",
              "      <th>Meg3</th>\n",
              "      <th>Ptn</th>\n",
              "      <th>Mt3</th>\n",
              "      <th>Tubb2b</th>\n",
              "      <th>Fabp7</th>\n",
              "      <th>Cst3</th>\n",
              "      <th>Xist</th>\n",
              "      <th>Sox11</th>\n",
              "      <th>Tubb3</th>\n",
              "      <th>Pcp4</th>\n",
              "      <th>Igfbpl1</th>\n",
              "      <th>Slc1a2</th>\n",
              "      <th>Slc1a3</th>\n",
              "      <th>Tubb5</th>\n",
              "      <th>Snca</th>\n",
              "      <th>Plp1</th>\n",
              "      <th>Atp1a2</th>\n",
              "      <th>Dbi</th>\n",
              "      <th>Nnat</th>\n",
              "      <th>Cd24a</th>\n",
              "      <th>Mt2</th>\n",
              "      <th>Ppp3ca</th>\n",
              "      <th>Ncdn</th>\n",
              "      <th>Gap43</th>\n",
              "      <th>Mllt11</th>\n",
              "      <th>Marcksl1</th>\n",
              "      <th>Aldoc</th>\n",
              "      <th>Camk2a</th>\n",
              "      <th>Plppr4</th>\n",
              "      <th>Clu</th>\n",
              "      <th>Glul</th>\n",
              "      <th>Ptprz1</th>\n",
              "      <th>Sparcl1</th>\n",
              "      <th>...</th>\n",
              "      <th>Shf</th>\n",
              "      <th>2610037D02Rik</th>\n",
              "      <th>Atxn7l2</th>\n",
              "      <th>Tmem74b</th>\n",
              "      <th>Adnp2</th>\n",
              "      <th>Arsg</th>\n",
              "      <th>Esco2</th>\n",
              "      <th>Tmtc3</th>\n",
              "      <th>Rnmtl1</th>\n",
              "      <th>Pald1</th>\n",
              "      <th>Dcp1a</th>\n",
              "      <th>Gemin2</th>\n",
              "      <th>Nckipsd</th>\n",
              "      <th>Notch3</th>\n",
              "      <th>Ubtd1</th>\n",
              "      <th>Simc1</th>\n",
              "      <th>Nkrf</th>\n",
              "      <th>Gabpb2</th>\n",
              "      <th>Fbxo10</th>\n",
              "      <th>Cenpl</th>\n",
              "      <th>Wdr36</th>\n",
              "      <th>Invs</th>\n",
              "      <th>Trim39</th>\n",
              "      <th>Ttc21b</th>\n",
              "      <th>Penk</th>\n",
              "      <th>Zfp629</th>\n",
              "      <th>D130020L05Rik</th>\n",
              "      <th>Pnpt1</th>\n",
              "      <th>Ice2</th>\n",
              "      <th>Pifo</th>\n",
              "      <th>Nol10</th>\n",
              "      <th>Gm6356</th>\n",
              "      <th>Tpmt</th>\n",
              "      <th>Gba</th>\n",
              "      <th>Slc25a20</th>\n",
              "      <th>Col19a1</th>\n",
              "      <th>Zfp516</th>\n",
              "      <th>Rgp1</th>\n",
              "      <th>Col26a1</th>\n",
              "      <th>Jpx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Neuroblast</td>\n",
              "      <td>4.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>3.09</td>\n",
              "      <td>4.62</td>\n",
              "      <td>3.72</td>\n",
              "      <td>4.04</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>3.81</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.43</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.63</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.88</td>\n",
              "      <td>3.01</td>\n",
              "      <td>3.59</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Immature-GC</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.76</td>\n",
              "      <td>0.84</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.65</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.63</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>2.96</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>3.54</td>\n",
              "      <td>2.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.68</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.44</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>1.29</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GC-juv</td>\n",
              "      <td>1.71</td>\n",
              "      <td>5.08</td>\n",
              "      <td>2.98</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3.97</td>\n",
              "      <td>3.32</td>\n",
              "      <td>1.57</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.62</td>\n",
              "      <td>3.15</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.92</td>\n",
              "      <td>4.98</td>\n",
              "      <td>2.72</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2.41</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2.23</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2.28</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.35</td>\n",
              "      <td>2.87</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CA3-Pyr</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>3.35</td>\n",
              "      <td>4.26</td>\n",
              "      <td>3.88</td>\n",
              "      <td>3.82</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.47</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.10</td>\n",
              "      <td>2.85</td>\n",
              "      <td>3.23</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.61</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.37</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.84</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GC-juv</td>\n",
              "      <td>1.91</td>\n",
              "      <td>4.08</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>2.67</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.10</td>\n",
              "      <td>4.69</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1.79</td>\n",
              "      <td>5.36</td>\n",
              "      <td>4.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.44</td>\n",
              "      <td>3.25</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.83</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.39</td>\n",
              "      <td>0.81</td>\n",
              "      <td>2.82</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.41</td>\n",
              "      <td>2.44</td>\n",
              "      <td>2.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.10</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2.83</td>\n",
              "      <td>2.98</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31f5c457-9a28-444d-9041-f9f3f09a1795')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31f5c457-9a28-444d-9041-f9f3f09a1795 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31f5c457-9a28-444d-9041-f9f3f09a1795');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         label  Tmsb10  Apoe   Mt1  Stmn2  ...  Col19a1  Zfp516  Rgp1  Col26a1   Jpx\n",
              "0   Neuroblast    4.47  0.00  0.35   3.09  ...      0.0     0.0  0.00     0.49  0.00\n",
              "1  Immature-GC    2.36  0.36  0.84   1.40  ...      0.0     0.0  0.36     0.00  0.00\n",
              "2       GC-juv    1.71  5.08  2.98   0.52  ...      0.0     0.0  0.20     0.00  0.00\n",
              "3      CA3-Pyr    4.29  0.20  0.20   3.35  ...      0.0     0.0  0.00     0.37  0.00\n",
              "4       GC-juv    1.91  4.08  3.24   0.41  ...      0.0     0.0  0.00     0.00  0.41\n",
              "\n",
              "[5 rows x 10001 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of zero per column to see how sparse our dataset is (%)\n",
        "print(dataframe.iloc[:, 1:].astype(bool).sum(axis=0) / dataframe.shape[0] *100)\n",
        "\n",
        "# Check the sparsity of our matrix\n",
        "sparr = dataframe.iloc[:, 1:].to_numpy()\n",
        "print(\"sparsity:\", (sparr == 0).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB10_Ip3pSlk",
        "outputId": "2e2223d3-c3b0-4cff-ac88-45b87ad6d360"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tmsb10     94.633333\n",
            "Apoe       87.700000\n",
            "Mt1        90.766667\n",
            "Stmn2      81.400000\n",
            "Tuba1a     99.200000\n",
            "             ...    \n",
            "Col19a1    13.533333\n",
            "Zfp516     24.866667\n",
            "Rgp1       34.266667\n",
            "Col26a1    14.000000\n",
            "Jpx        31.733333\n",
            "Length: 10000, dtype: float64\n",
            "sparsity: 0.39000076666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset is quite sparse (40% of the data is equals to 0)."
      ],
      "metadata": {
        "id": "6LUjyZHMzfCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.astype(bool).sum(axis=0)"
      ],
      "metadata": {
        "id": "eG1mVHk5y7p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating labels from data\n",
        "cell_labels = dataframe[\"label\"].copy()\n",
        "df = dataframe.iloc[:, 1:].copy()\n",
        "\n",
        "\n",
        "# Standardizing our data\n",
        "scaler = StandardScaler() \n",
        "data_scaled = scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "7uHKnvqPoKU6"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mean:\", data_scaled.mean(axis=0))\n",
        "print(\"std:\", data_scaled.std(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBVSqZxpqsA1",
        "outputId": "abb6eabb-069d-44a2-a16d-404a6243adcd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: [ 3.11454566e-16 -2.81256500e-17 -5.74355378e-17 ... -5.86197757e-17\n",
            "  7.10542736e-18 -6.33567273e-17]\n",
            "std: [1. 1. 1. ... 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to use Standard Scalar over Min max as it will not lower the variance like MinMax (useful when using PCA). Moreover, we will consider the effect of outliers important, as we want to visualize the data, thus keeping the standard scalar normalization.\n",
        "\n",
        "However, our dataset is quite sparse (around 40% data). Using traditional scaling methods aren't the best solution in this case. Indeed, both of these methods will make the center shift and will \"break\" the sparsity.\n",
        "\n",
        "We can use instead **MaxAbsScalar**.\n",
        "\n",
        "Scale each feature by its maximum absolute value. This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.0. It does not shift/center the data, and thus does not destroy any sparsity.\n"
      ],
      "metadata": {
        "id": "HDDqVJH5vQiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "scaler = MaxAbsScaler()\n",
        "data_scaled = scaler.fit_transform(df)\n",
        "standardized_dataset = scaler.transform(df)\n",
        "print(standardized_dataset)"
      ],
      "metadata": {
        "id": "rY50fXGDM-r-",
        "outputId": "96f3459d-8127-4f0b-87d6-2d755d0a2237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.83395522 0.         0.05376344 ... 0.         0.2816092  0.        ]\n",
            " [0.44029851 0.05454545 0.12903226 ... 0.47368421 0.         0.        ]\n",
            " [0.31902985 0.76969697 0.4577573  ... 0.26315789 0.         0.        ]\n",
            " ...\n",
            " [0.         0.17575758 0.32104455 ... 0.         0.         0.        ]\n",
            " [0.76865672 0.0469697  0.02611367 ... 0.22368421 0.17816092 0.        ]\n",
            " [0.92910448 0.02424242 0.         ... 0.21052632 0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are preserving the sparsity of our dataset."
      ],
      "metadata": {
        "id": "G9YwNxU1Ni7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.4 Give an estimate of intrinsic dimensionality of the dataset"
      ],
      "metadata": {
        "id": "k5OMqRQo6FRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.5  Apply PCA and visualize the dataset in the space of two first principal components"
      ],
      "metadata": {
        "id": "EXqAbjWn6Izn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.6 Investigate higher-order principal components, try to conclude if they contain useful information"
      ],
      "metadata": {
        "id": "lCgjj7bn6NjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.7 Apply any non-linear manifold learning method and visualize the dataset"
      ],
      "metadata": {
        "id": "6aOnpL2R6TTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.8  Apply two or more different clustering methods using clustering quality criteria, compare the results as well as computational time"
      ],
      "metadata": {
        "id": "uNxgnZlr6XXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q.9 Apply any matrix factorization method which is not PCA, compare it with PCA as well as computational time"
      ],
      "metadata": {
        "id": "ABUQwkei6daL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fun-UngUf3NO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}